{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:23:50.923926Z",
     "start_time": "2025-11-14T23:23:50.250408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import base64\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()  # reads .env file\n",
    "\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), base_url='https://api.proxyapi.ru/openai/v1')\n",
    "claude_client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n"
   ],
   "id": "d1a421ba633fbc5f",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:23:50.936432Z",
     "start_time": "2025-11-14T23:23:50.929839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_openai(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img_b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Classify the car in the image as 'sports' or 'civilian'. Respond with one word only.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_b64}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    message_content = response.choices[0].message.content\n",
    "    if isinstance(message_content, list):\n",
    "        message_content = message_content[0].text\n",
    "\n",
    "    return message_content.strip().lower()\n",
    "\n",
    "\n",
    "def classify_claude(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    response = claude_client.messages.create(\n",
    "        model=\"claude-haiku-4-5-20251001\",\n",
    "        max_tokens=10,\n",
    "        messages=[\n",
    "            {\"role\": \"user\",\n",
    "             \"content\": [\n",
    "                 {\"type\": \"text\", \"text\": \"Classify this car as 'sports' or 'civilian'. Answer only one word.\"},\n",
    "                 {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": b64}}\n",
    "             ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.content[0].text.strip().lower()\n"
   ],
   "id": "a0065528abf2578f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:23:50.952424Z",
     "start_time": "2025-11-14T23:23:50.945228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collect_dataset(root=\"data/images\"):\n",
    "    records = []\n",
    "    for label in [\"civilian\", \"sports\"]:\n",
    "        folder = os.path.join(root, label)\n",
    "        for fn in sorted(os.listdir(folder)):\n",
    "            if fn.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
    "                records.append((os.path.join(folder, fn), label))\n",
    "    return records\n",
    "\n",
    "dataset = collect_dataset()\n",
    "dataset[:5]\n"
   ],
   "id": "d8e4c508b474446",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/images\\\\civilian\\\\0001.jpg', 'civilian'),\n",
       " ('data/images\\\\civilian\\\\0002.jpeg', 'civilian'),\n",
       " ('data/images\\\\civilian\\\\0003.jpeg', 'civilian'),\n",
       " ('data/images\\\\civilian\\\\0004.jpg', 'civilian'),\n",
       " ('data/images\\\\civilian\\\\0005.jpg', 'civilian')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:28:15.107543Z",
     "start_time": "2025-11-14T23:23:50.967856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "openai_preds = []\n",
    "claude_preds = []\n",
    "true_labels = []\n",
    "\n",
    "\n",
    "for path, label in tqdm(dataset):\n",
    "    true_labels.append(label)\n",
    "    openai_preds.append(classify_openai(path))\n",
    "    claude_preds.append(classify_claude(path))\n"
   ],
   "id": "fee50a497eea5aab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:24<00:00,  8.80s/it]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:28:15.164377Z",
     "start_time": "2025-11-14T23:28:15.130707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=== RESULTS ===\")\n",
    "print(\"\\nOpenAI accuracy:\", accuracy_score(true_labels, openai_preds))\n",
    "print(\"Claude accuracy:\", accuracy_score(true_labels, claude_preds))\n",
    "\n",
    "print(\"\\nOpenAI confusion matrix:\\n\", confusion_matrix(true_labels, openai_preds))\n",
    "print(\"\\nClaude confusion matrix:\\n\", confusion_matrix(true_labels, claude_preds))\n",
    "\n",
    "print(\"\\nOpenAI detailed report:\\n\", classification_report(true_labels, openai_preds))\n",
    "print(\"\\nClaude detailed report:\\n\", classification_report(true_labels, claude_preds))\n"
   ],
   "id": "6413880698b0ae85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESULTS ===\n",
      "\n",
      "OpenAI accuracy: 0.8333333333333334\n",
      "Claude accuracy: 0.7666666666666667\n",
      "\n",
      "OpenAI confusion matrix:\n",
      " [[11  0  4]\n",
      " [ 0  0  0]\n",
      " [ 0  1 14]]\n",
      "\n",
      "Claude confusion matrix:\n",
      " [[ 8  7]\n",
      " [ 0 15]]\n",
      "\n",
      "OpenAI detailed report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    civilian       1.00      0.73      0.85        15\n",
      "   civilian.       0.00      0.00      0.00         0\n",
      "      sports       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.59      0.56      0.56        30\n",
      "weighted avg       0.89      0.83      0.85        30\n",
      "\n",
      "\n",
      "Claude detailed report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    civilian       1.00      0.53      0.70        15\n",
      "      sports       0.68      1.00      0.81        15\n",
      "\n",
      "    accuracy                           0.77        30\n",
      "   macro avg       0.84      0.77      0.75        30\n",
      "weighted avg       0.84      0.77      0.75        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1\\PycharmProjects\\MIREA-ISiT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\1\\PycharmProjects\\MIREA-ISiT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\1\\PycharmProjects\\MIREA-ISiT\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:28:15.184655Z",
     "start_time": "2025-11-14T23:28:15.179536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Misclassified cases ===\\n\")\n",
    "\n",
    "for (path, true), o, c in zip(dataset, openai_preds, claude_preds):\n",
    "    if o != true or c != true:\n",
    "        print(f\"{path}: true={true}, openai={o}, claude={c}\")\n"
   ],
   "id": "3b4cbf9fcdc3d97e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Misclassified cases ===\n",
      "\n",
      "data/images\\civilian\\0002.jpeg: true=civilian, openai=civilian, claude=sports\n",
      "data/images\\civilian\\0004.jpg: true=civilian, openai=sports, claude=sports\n",
      "data/images\\civilian\\0006.jpg: true=civilian, openai=civilian, claude=sports\n",
      "data/images\\civilian\\0008.jpg: true=civilian, openai=civilian, claude=sports\n",
      "data/images\\civilian\\0010.jpg: true=civilian, openai=sports, claude=sports\n",
      "data/images\\civilian\\0014.jpg: true=civilian, openai=sports, claude=sports\n",
      "data/images\\civilian\\0015.jpg: true=civilian, openai=sports, claude=sports\n",
      "data/images\\sports\\0014.jpg: true=sports, openai=civilian., claude=sports\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:28:15.216617Z",
     "start_time": "2025-11-14T23:28:15.211926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "================== SUMMARY ==================\n",
    "• Модели сравнивались на 30 изображениях\n",
    "• Классификация: sports vs civilian\n",
    "• Использованные LLM: GPT-4o-mini-vision и Claude 3.5 Sonnet Vision\n",
    "\n",
    "Анализ ошибок и результаты можно использовать в отчёте.\n",
    "==============================================\n",
    "\"\"\")\n"
   ],
   "id": "490622d1c0c5a89b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== SUMMARY ==================\n",
      "• Модели сравнивались на 30 изображениях\n",
      "• Классификация: sports vs civilian\n",
      "• Использованные LLM: GPT-4o-mini-vision и Claude 3.5 Sonnet Vision\n",
      "\n",
      "Анализ ошибок и результаты можно использовать в отчёте.\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
